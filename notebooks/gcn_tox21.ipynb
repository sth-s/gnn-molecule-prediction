{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805f2018",
   "metadata": {
    "id": "805f2018"
   },
   "source": [
    "# Molecular Toxicity Prediction (Tox21) using GCN\n",
    "\n",
    "In this notebook, we implement and train a Graph Convolutional Network for predicting molecular toxicity based on the Tox21 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1ce29",
   "metadata": {
    "id": "2fc1ce29"
   },
   "source": [
    "## 1. Environment Setup in Colab\n",
    "\n",
    "Run the following code to install PyTorch Geometric and other dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728976d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a728976d",
    "outputId": "e2b53cff-a1f7-48f0-83cd-e6d22bd4b0f5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# This cell is intended to be run only in Google Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Running in Colab...\")\n",
    "\n",
    "    # 1. Remove existing folder if it already exists\n",
    "    repo_name = 'gnn-molecule-prediction'\n",
    "    repo_path = os.path.join('/content', repo_name)\n",
    "\n",
    "    if os.path.exists(repo_path):\n",
    "        shutil.rmtree(repo_path)\n",
    "        print(f\"Removed existing directory: {repo_path}\")\n",
    "    else:\n",
    "        print(f\"No existing directory found: {repo_path}\")\n",
    "\n",
    "    # 2. Clone the GitHub repository\n",
    "    %cd /content\n",
    "    !git clone https://github.com/sth-s/gnn-molecule-prediction.git\n",
    "\n",
    "    # 3. Change working directory to the project root\n",
    "    %cd gnn-molecule-prediction\n",
    "\n",
    "    # 4. Install Conda support in Colab and restart runtime\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()  # This will automatically restart the runtime\n",
    "    !conda env update -n base -f environment.yml\n",
    "    %cd gnn-molecule-prediction\n",
    "\n",
    "else:\n",
    "    os.chdir('../')\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e18f8",
   "metadata": {
    "id": "8d9e18f8"
   },
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd14e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abbd14e8",
    "outputId": "86dcebe8-1cca-4283-a665-b55f9b34c6a3"
   },
   "outputs": [],
   "source": [
    "# PyTorch and PyG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Chemistry and data processing\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluation and splitting\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Our custom data loader\n",
    "from src.data_utils import load_tox21\n",
    "# Import our custom model and training functions\n",
    "from src.model import GCN\n",
    "from src.train import train_epoch, evaluate\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette('muted')\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4b6a6",
   "metadata": {
    "id": "88d4b6a6"
   },
   "source": [
    "## 3. Loading and Preparing Tox21 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8479b",
   "metadata": {},
   "source": [
    "### 3.1 About the Data Loading Module\n",
    "\n",
    "We use a custom developed `load_tox21` module from the `src.data_utils` package, which provides the following features:\n",
    "\n",
    "- **Automatic data downloading**: if the `tox21.csv` file is missing, the module will automatically download it from the official source\n",
    "- **SMILES to graphs conversion**: each molecule is converted into a graph with node and edge attributes\n",
    "- **Result caching**: results are saved to a cache to speed up subsequent runs\n",
    "- **Flexible configuration**: you can specify the data path, file name, target columns, and other parameters\n",
    "\n",
    "Detailed information about the `load_tox21` function and usage examples are available in the project's README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13aa5d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f13aa5d7",
    "outputId": "626237d6-39e2-4ebd-f009-3d9d26af8521"
   },
   "outputs": [],
   "source": [
    "# Load the Tox21 dataset using our custom function\n",
    "# If the tox21.csv file is missing, it will be automatically downloaded\n",
    "dataset = load_tox21(\n",
    "    root=\"data/Tox21\",           # root directory for the data\n",
    "    filename=\"tox21.csv\",        # name of the CSV file\n",
    "    smiles_col=\"smiles\",         # column containing SMILES strings\n",
    "    mol_id_col=\"mol_id\",         # column containing molecule IDs\n",
    "    cache_file=\"data.pt\",        # name of the cache file\n",
    "    recreate=False,              # Use existing processed file if available\n",
    "    auto_download=True           # automatically download if missing\n",
    ")\n",
    "\n",
    "print(f\"Type of dataset object: {type(dataset)}\")\n",
    "try:\n",
    "    print(f\"dataset._slices: {dataset._slices}\")\n",
    "except AttributeError:\n",
    "    print(f\"dataset has no attribute _slices\")\n",
    "print(f\"Total graphs (len(dataset)): {len(dataset)}\")\n",
    "\n",
    "# Check if we can access the first item in the dataset\n",
    "if len(dataset) > 0:\n",
    "    print(\"Attempting to access dataset[0]...\")\n",
    "    first_item = None\n",
    "    try:\n",
    "        first_item = dataset[0]\n",
    "        print(f\"dataset[0] type: {type(first_item)}\")\n",
    "        if first_item is not None:\n",
    "            print(f\"Number of node features: {first_item.x.shape[1]}\")\n",
    "            if hasattr(first_item, 'mol_id'):\n",
    "                 print(f\"Mol ID for the first molecule: {first_item.mol_id}\")\n",
    "            else:\n",
    "                 print(f\"Mol ID attribute not found in first_item.\")\n",
    "            \n",
    "            # Check the presence of y and y_mask\n",
    "            if hasattr(first_item, 'y'):\n",
    "                print(f\"Task labels (y) shape: {first_item.y.shape}\")\n",
    "                print(f\"Task labels (y): {first_item.y}\")\n",
    "            if hasattr(first_item, 'y_mask'):\n",
    "                print(f\"Task mask (y_mask) shape: {first_item.y_mask.shape}\")\n",
    "                print(f\"Task mask (y_mask): {first_item.y_mask}\")\n",
    "        else:\n",
    "            print(f\"dataset[0] is None.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing dataset[0] or its attributes: {e}\")\n",
    "else:\n",
    "    print(\"Dataset is empty (len(dataset) is 0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698e268",
   "metadata": {},
   "source": [
    "### 3.3 Verify mol_id and Dataset Properties (Revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that mol_id is present and check dataset properties\n",
    "print(\"\\nRunning second verification cell:\")\n",
    "if len(dataset) > 0:\n",
    "    data_example = None\n",
    "    try:\n",
    "        data_example = dataset[0] # This might be None if the previous cell showed it was None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting dataset[0] in second cell: {e}\")\n",
    "    \n",
    "    if data_example is not None:\n",
    "        print(\"Example graph from the dataset (after potential reprocessing):\")\n",
    "        print(data_example)\n",
    "        \n",
    "        if hasattr(data_example, 'mol_id'):\n",
    "            print(f\"\\nMol ID for the first molecule: {data_example.mol_id}\")\n",
    "        else:\n",
    "            print(\"\\nmol_id attribute not found in the first molecule (data_example).\")\n",
    "        \n",
    "        print(f\"Edge index dimensions: {data_example.edge_index.shape}\")\n",
    "        print(f\"Number of atoms (nodes): {data_example.num_nodes}\")\n",
    "        print(f\"Task labels (y): {data_example.y}\")\n",
    "        print(f\"Task mask (y_mask): {data_example.y_mask}\")\n",
    "    elif len(dataset) > 0: # dataset[0] was None but dataset is not empty\n",
    "        print(\"data_example (dataset[0]) is None, cannot print details.\")\n",
    "else:\n",
    "    print(\"Dataset is empty in second verification cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of graph properties in the dataset\n",
    "if len(dataset) > 0:\n",
    "    data_example = dataset[0]\n",
    "    print(\"Example graph from the dataset:\")\n",
    "    print(data_example)\n",
    "    print(f\"Edge index dimensions: {data_example.edge_index.shape}\")\n",
    "    print(f\"Number of atoms (nodes): {data_example.num_nodes}\")\n",
    "    print(f\"Task labels (y): {data_example.y}\")\n",
    "\n",
    "    # Dataset statistics\n",
    "    nodes_count = []\n",
    "    edges_count = []\n",
    "    for i in range(min(1000, len(dataset))):\n",
    "        data = dataset[i]\n",
    "        nodes_count.append(data.num_nodes)\n",
    "        edges_count.append(data.edge_index.shape[1])\n",
    "    \n",
    "    print(f\"\\nGraph statistics (based on a sample of {len(nodes_count)} molecules):\")\n",
    "    print(f\"Average number of atoms: {np.mean(nodes_count):.2f} ± {np.std(nodes_count):.2f}\")\n",
    "    print(f\"Average number of bonds: {np.mean(edges_count)/2:.2f} ± {np.std(edges_count)/2:.2f}\")\n",
    "    print(f\"Min/max atoms: {np.min(nodes_count)}/{np.max(nodes_count)}\")\n",
    "    print(f\"Min/max bonds: {np.min(edges_count)/2:.0f}/{np.max(edges_count)/2:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of atom and bond count distributions\n",
    "if 'nodes_count' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax1.hist(nodes_count, bins=30, alpha=0.7, color='skyblue')\n",
    "    ax1.set_title('Distribution of Atom Counts')\n",
    "    ax1.set_xlabel('Number of atoms')\n",
    "    ax1.set_ylabel('Number of molecules')\n",
    "    \n",
    "    ax2.hist([e/2 for e in edges_count], bins=30, alpha=0.7, color='salmon')\n",
    "    ax2.set_title('Distribution of Bond Counts')\n",
    "    ax2.set_xlabel('Number of bonds')\n",
    "    ax2.set_ylabel('Number of molecules')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test (80/20)\n",
    "torch.manual_seed(42)  # for reproducibility\n",
    "train_len = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_len, len(dataset) - train_len]\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Total graphs: {len(dataset)}\")\n",
    "print(f\"Training set: {len(train_dataset)} graphs\")\n",
    "print(f\"Test set: {len(test_dataset)} graphs\")\n",
    "print(f\"Batch size: {train_loader.batch_size}, number of batches in training set: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848f580",
   "metadata": {
    "id": "5848f580"
   },
   "source": [
    "## 4. Define GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859471d7",
   "metadata": {
    "id": "859471d7"
   },
   "outputs": [],
   "source": [
    "# Create a GCN model instance using our implementation from src/model.py\n",
    "model = GCN(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    num_classes=dataset.num_classes,\n",
    "    num_layers=2,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(f\"Model created with {dataset.num_node_features} input features and {dataset.num_classes} output classes\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8c0a9",
   "metadata": {
    "id": "e5d8c0a9"
   },
   "source": [
    "## 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb0b32",
   "metadata": {
    "id": "eadb0b32"
   },
   "outputs": [],
   "source": [
    "# Training and evaluation using our functions from src/train.py\n",
    "num_epochs = 20\n",
    "best_val_roc = 0\n",
    "best_model_state = None\n",
    "history = {'train_loss': [], 'val_roc': [], 'val_pr': []}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train for one epoch\n",
    "    loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_metrics = evaluate(model, test_loader, device)\n",
    "    val_roc = val_metrics['roc_auc']\n",
    "    val_pr = val_metrics['pr_auc']\n",
    "    \n",
    "    # Save metrics history\n",
    "    history['train_loss'].append(loss)\n",
    "    history['val_roc'].append(val_roc)\n",
    "    history['val_pr'].append(val_pr)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch:02d}: Loss = {loss:.4f}, ROC AUC = {val_roc:.4f}, PR AUC = {val_pr:.4f}\")\n",
    "    \n",
    "    # Save best model state\n",
    "    if val_roc > best_val_roc:\n",
    "        best_val_roc = val_roc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  → New best model saved! ROC AUC: {best_val_roc:.4f}\")\n",
    "\n",
    "# Load the best model state for final evaluation\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Loaded best model with validation ROC AUC: {best_val_roc:.4f}\")\n",
    "\n",
    "# Perform final evaluation\n",
    "final_metrics = evaluate(model, test_loader, device)\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(f\"Test ROC AUC: {final_metrics['roc_auc']:.4f}\")\n",
    "print(f\"Test PR AUC: {final_metrics['pr_auc']:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model_state, 'best_gcn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3328c",
   "metadata": {
    "id": "a2a3328c"
   },
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb9775",
   "metadata": {
    "id": "cffb9775"
   },
   "outputs": [],
   "source": [
    "# Visualize learning curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(history['train_loss'])+1), history['train_loss'], 'o-', label='Training Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation ROC AUC\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(history['val_roc'])+1), history['val_roc'], 'o-', label='ROC AUC')\n",
    "plt.plot(range(1, len(history['val_pr'])+1), history['val_pr'], 'o-', label='PR AUC')\n",
    "plt.title('Validation Metrics per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC and PR curves for the three best endpoints\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions for each task\n",
    "all_true = {}\n",
    "all_pred = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch).sigmoid().detach().cpu()\n",
    "        mask = batch.y_mask.cpu()\n",
    "        y = batch.y.cpu()\n",
    "        \n",
    "        for task in range(out.size(1)):\n",
    "            idx = mask[:, task]\n",
    "            if idx.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            true = y[idx, task].numpy()\n",
    "            pred = out[idx, task].numpy()\n",
    "            \n",
    "            all_true.setdefault(task, []).append(true)\n",
    "            all_pred.setdefault(task, []).append(pred)\n",
    "\n",
    "# Calculate AUC for each task\n",
    "task_metrics = {}\n",
    "for task in all_true:\n",
    "    t = np.concatenate(all_true[task])\n",
    "    p = np.concatenate(all_pred[task])\n",
    "    \n",
    "    # Skip if only one class is present\n",
    "    if len(np.unique(t)) < 2:\n",
    "        continue\n",
    "        \n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(t, p)\n",
    "    \n",
    "    # Calculate PR AUC\n",
    "    prec, rec, _ = precision_recall_curve(t, p)\n",
    "    pr_auc = auc(rec, prec)\n",
    "    \n",
    "    # Store task metrics and raw predictions for plotting\n",
    "    task_metrics[task] = {\n",
    "        'roc_auc': roc_auc, \n",
    "        'pr_auc': pr_auc,\n",
    "        'true': t,\n",
    "        'pred': p\n",
    "    }\n",
    "\n",
    "# Find the three best endpoints based on ROC AUC\n",
    "best_tasks = sorted(task_metrics.keys(), key=lambda x: task_metrics[x]['roc_auc'], reverse=True)[:3]\n",
    "print(f\"Three best endpoints (task indices): {best_tasks}\")\n",
    "\n",
    "# Plot ROC curves for the three best endpoints\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC Curves\n",
    "plt.subplot(1, 2, 1)\n",
    "for task in best_tasks:\n",
    "    t = task_metrics[task]['true']\n",
    "    p = task_metrics[task]['pred']\n",
    "    fpr, tpr, _ = roc_curve(t, p)\n",
    "    plt.plot(fpr, tpr, label=f'Task {task} (AUC = {task_metrics[task][\"roc_auc\"]:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Best Endpoints')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# PR Curves\n",
    "plt.subplot(1, 2, 2)\n",
    "for task in best_tasks:\n",
    "    t = task_metrics[task]['true']\n",
    "    p = task_metrics[task]['pred']\n",
    "    prec, rec, _ = precision_recall_curve(t, p)\n",
    "    plt.plot(rec, prec, label=f'Task {task} (AUC = {task_metrics[task][\"pr_auc\"]:.3f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR Curves for Best Endpoints')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4221e",
   "metadata": {
    "id": "7eb4221e"
   },
   "source": [
    "## 7. Conclusion and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902fe8d",
   "metadata": {
    "id": "5902fe8d"
   },
   "source": [
    "# TODO: Add analysis of results and conclusions"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (gnn-tox21)",
   "language": "python",
   "name": "gnn-tox21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
