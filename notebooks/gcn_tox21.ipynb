{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805f2018",
   "metadata": {
    "id": "805f2018"
   },
   "source": [
    "# Molecular Toxicity Prediction (Tox21) using GIN\n",
    "\n",
    "In this notebook, we implement and train a Graph Isomorphism Network (GIN) for predicting molecular toxicity based on the Tox21 dataset. GIN is generally more powerful than GCN for graph representation learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1ce29",
   "metadata": {
    "id": "2fc1ce29"
   },
   "source": [
    "## 1. Environment Setup in Colab\n",
    "\n",
    "Run the following code to install PyTorch Geometric and other dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728976d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a728976d",
    "outputId": "e2b53cff-a1f7-48f0-83cd-e6d22bd4b0f5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# This cell is intended to be run only in Google Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Running in Colab...\")\n",
    "\n",
    "    # 1. Remove existing folder if it already exists\n",
    "    repo_name = 'gnn-molecule-prediction'\n",
    "    repo_path = os.path.join('/content', repo_name)\n",
    "\n",
    "    if os.path.exists(repo_path):\n",
    "        shutil.rmtree(repo_path)\n",
    "        print(f\"Removed: {repo_path}\")\n",
    "    else:\n",
    "        print(f\"No existing directory found.\")\n",
    "\n",
    "    # 2. Clone the GitHub repository\n",
    "    %cd /content\n",
    "    !git clone https://github.com/sth-s/gnn-molecule-prediction.git\n",
    "\n",
    "    # 3. Change working directory to the project root\n",
    "    %cd gnn-molecule-prediction\n",
    "\n",
    "    # 4. Install dependencies via pip\n",
    "    !pip install torch torchvision torchaudio\n",
    "    !pip install torch-geometric scikit-learn matplotlib seaborn deepchem\n",
    "\n",
    "    print(\"Dependencies installed.\")\n",
    "\n",
    "else:\n",
    "    os.chdir('../')\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e18f8",
   "metadata": {
    "id": "8d9e18f8"
   },
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd14e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abbd14e8",
    "outputId": "86dcebe8-1cca-4283-a665-b55f9b34c6a3"
   },
   "outputs": [],
   "source": [
    "# PyTorch and PyG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GINConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# Chemistry and data processing\n",
    "import deepchem as dc\n",
    "from deepchem.feat.graph_data import GraphData\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluation and splitting\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Our custom data loader\n",
    "from src.data_utils import load_tox21\n",
    "# Import our custom model and training functions\n",
    "from src.model import GIN\n",
    "from src.train import train_epoch, evaluate\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette('muted')\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4b6a6",
   "metadata": {
    "id": "88d4b6a6"
   },
   "source": [
    "## 3. Loading and Preparing Tox21 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8479b",
   "metadata": {},
   "source": [
    "### 3.1 About the Data Loading Module\n",
    "\n",
    "We use a custom developed `load_tox21` module from the `src.data_utils` package, which provides the following features:\n",
    "\n",
    "- **Automatic data downloading**: if the `tox21.csv` file is missing, the module will automatically download it from the official source\n",
    "- **SMILES to graphs conversion**: each molecule is converted into a graph with node and edge attributes\n",
    "- **Result caching**: results are saved to a cache to speed up subsequent runs\n",
    "- **Flexible configuration**: you can specify the data path, file name, target columns, and other parameters\n",
    "\n",
    "Detailed information about the `load_tox21` function and usage examples are available in the project's README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13aa5d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f13aa5d7",
    "outputId": "626237d6-39e2-4ebd-f009-3d9d26af8521"
   },
   "outputs": [],
   "source": [
    "# Load the Tox21 dataset using our custom function\n",
    "# If the tox21.csv file is missing, it will be automatically downloaded\n",
    "dataset = load_tox21(\n",
    "    root=\"data/Tox21\",           # root directory for the data\n",
    "    filename=\"tox21.csv\",        # name of the CSV file\n",
    "    smiles_col=\"smiles\",         # column containing SMILES strings\n",
    "    mol_id_col=\"mol_id\",         # column containing molecule IDs\n",
    "    cache_file=\"data.pt\",        # name of the cache file\n",
    "    recreate=False,              # Use existing processed file if available\n",
    "    auto_download=True           # automatically download if missing\n",
    ")\n",
    "\n",
    "print(f\"Type of dataset object: {type(dataset)}\")\n",
    "try:\n",
    "    print(f\"dataset._slices: {dataset._slices}\")\n",
    "except AttributeError:\n",
    "    print(f\"dataset has no attribute _slices\")\n",
    "print(f\"Total graphs (len(dataset)): {len(dataset)}\")\n",
    "\n",
    "# Check if we can access the first item in the dataset\n",
    "if len(dataset) > 0:\n",
    "    print(\"Attempting to access dataset[0]...\")\n",
    "    first_item = None\n",
    "    try:\n",
    "        first_item = dataset[0]\n",
    "        print(f\"dataset[0] type: {type(first_item)}\")\n",
    "        if first_item is not None:\n",
    "            print(f\"Number of node features: {first_item.x.shape[1]}\")\n",
    "            if hasattr(first_item, 'mol_id'):\n",
    "                 print(f\"Mol ID for the first molecule: {first_item.mol_id}\")\n",
    "            else:\n",
    "                 print(f\"Mol ID attribute not found in first_item.\")\n",
    "            \n",
    "            # Check the presence of y and y_mask\n",
    "            if hasattr(first_item, 'y'):\n",
    "                print(f\"Task labels (y) shape: {first_item.y.shape}\")\n",
    "                print(f\"Task labels (y): {first_item.y}\")\n",
    "            if hasattr(first_item, 'y_mask'):\n",
    "                print(f\"Task mask (y_mask) shape: {first_item.y_mask.shape}\")\n",
    "                print(f\"Task mask (y_mask): {first_item.y_mask}\")\n",
    "        else:\n",
    "            print(f\"dataset[0] is None.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing dataset[0] or its attributes: {e}\")\n",
    "else:\n",
    "    print(\"Dataset is empty (len(dataset) is 0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698e268",
   "metadata": {},
   "source": [
    "### 3.3 Verify mol_id and Dataset Properties (Revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that mol_id is present and check dataset properties\n",
    "print(\"\\nRunning second verification cell:\")\n",
    "if len(dataset) > 0:\n",
    "    data_example = None\n",
    "    try:\n",
    "        data_example = dataset[0] # This might be None if the previous cell showed it was None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting dataset[0] in second cell: {e}\")\n",
    "    \n",
    "    if data_example is not None:\n",
    "        print(\"Example graph from the dataset (after potential reprocessing):\")\n",
    "        print(data_example)\n",
    "        \n",
    "        if hasattr(data_example, 'mol_id'):\n",
    "            print(f\"\\nMol ID for the first molecule: {data_example.mol_id}\")\n",
    "        else:\n",
    "            print(\"\\nmol_id attribute not found in the first molecule (data_example).\")\n",
    "        \n",
    "        print(f\"Edge index dimensions: {data_example.edge_index.shape}\")\n",
    "        print(f\"Number of atoms (nodes): {data_example.num_nodes}\")\n",
    "        print(f\"Task labels (y): {data_example.y}\")\n",
    "        print(f\"Task mask (y_mask): {data_example.y_mask}\")\n",
    "    elif len(dataset) > 0: # dataset[0] was None but dataset is not empty\n",
    "        print(\"data_example (dataset[0]) is None, cannot print details.\")\n",
    "else:\n",
    "    print(\"Dataset is empty in second verification cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of graph properties in the dataset\n",
    "if len(dataset) > 0:\n",
    "    data_example = dataset[0]\n",
    "    print(\"Example graph from the dataset:\")\n",
    "    print(data_example)\n",
    "    print(f\"Edge index dimensions: {data_example.edge_index.shape}\")\n",
    "    print(f\"Number of atoms (nodes): {data_example.num_nodes}\")\n",
    "    print(f\"Task labels (y): {data_example.y}\")\n",
    "\n",
    "    # Dataset statistics\n",
    "    nodes_count = []\n",
    "    edges_count = []\n",
    "    for i in range(min(1000, len(dataset))):\n",
    "        data = dataset[i]\n",
    "        nodes_count.append(data.num_nodes)\n",
    "        edges_count.append(data.edge_index.shape[1])\n",
    "    \n",
    "    print(f\"\\nGraph statistics (based on a sample of {len(nodes_count)} molecules):\")\n",
    "    print(f\"Average number of atoms: {np.mean(nodes_count):.2f} ± {np.std(nodes_count):.2f}\")\n",
    "    print(f\"Average number of bonds: {np.mean(edges_count)/2:.2f} ± {np.std(edges_count)/2:.2f}\")\n",
    "    print(f\"Min/max atoms: {np.min(nodes_count)}/{np.max(nodes_count)}\")\n",
    "    print(f\"Min/max bonds: {np.min(edges_count)/2:.0f}/{np.max(edges_count)/2:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of atom and bond count distributions\n",
    "if 'nodes_count' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax1.hist(nodes_count, bins=30, alpha=0.7, color='skyblue')\n",
    "    ax1.set_title('Distribution of Atom Counts')\n",
    "    ax1.set_xlabel('Number of atoms')\n",
    "    ax1.set_ylabel('Number of molecules')\n",
    "    \n",
    "    ax2.hist([e/2 for e in edges_count], bins=30, alpha=0.7, color='salmon')\n",
    "    ax2.set_title('Distribution of Bond Counts')\n",
    "    ax2.set_xlabel('Number of bonds')\n",
    "    ax2.set_ylabel('Number of molecules')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test (80/20)\n",
    "torch.manual_seed(42)  # for reproducibility\n",
    "train_len = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_len, len(dataset) - train_len]\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Total graphs: {len(dataset)}\")\n",
    "print(f\"Training set: {len(train_dataset)} graphs\")\n",
    "print(f\"Test set: {len(test_dataset)} graphs\")\n",
    "print(f\"Batch size: {train_loader.batch_size}, number of batches in training set: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848f580",
   "metadata": {
    "id": "5848f580"
   },
   "source": [
    "## 4. Define GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859471d7",
   "metadata": {
    "id": "859471d7"
   },
   "outputs": [],
   "source": [
    "# Create a GIN model instance using our implementation from src/model.py\n",
    "model = GIN(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    num_classes=dataset.num_classes,\n",
    "    num_layers=2,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "# Base learning rate for the optimizer\n",
    "base_lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
    "\n",
    "# Configure OneCycleLR scheduler\n",
    "# total_steps - total number of training steps (epochs * batches)\n",
    "num_epochs = 20\n",
    "total_steps = num_epochs * len(train_loader)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=base_lr * 10,  # maximum learning rate (10x base rate)\n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.3,        # percentage of steps for lr increase (30%)\n",
    "    anneal_strategy='cos',  # learning rate decay strategy (cosine)\n",
    "    div_factor=10.0,      # initial lr = max_lr / div_factor\n",
    "    final_div_factor=1000.0  # final lr = max_lr / final_div_factor\n",
    ")\n",
    "\n",
    "print(f\"Model created with {dataset.num_node_features} input features and {dataset.num_classes} output classes\")\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__} with base lr={base_lr}\")\n",
    "print(f\"Scheduler: OneCycleLR with max_lr={base_lr * 10}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8c0a9",
   "metadata": {
    "id": "e5d8c0a9"
   },
   "source": [
    "## 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb0b32",
   "metadata": {
    "id": "eadb0b32"
   },
   "outputs": [],
   "source": [
    "# Training and evaluation using our functions from src/train.py\n",
    "num_epochs = 20\n",
    "best_val_roc = 0\n",
    "best_model_state = None\n",
    "history = {\n",
    "    'train_loss': [], \n",
    "    'train_roc_auc': [], \n",
    "    'train_pr_auc': [],\n",
    "    'val_loss': [],\n",
    "    'val_roc': [], \n",
    "    'val_pr': [], \n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "print(\"Starting training with OneCycleLR scheduler...\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train for one epoch with scheduler\n",
    "    train_results, lr_history = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
    "    train_loss = train_results['loss']\n",
    "    train_roc = train_results['roc_auc']\n",
    "    train_pr = train_results['pr_auc']\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_metrics = evaluate(model, test_loader, device)\n",
    "    val_loss = val_metrics['loss']\n",
    "    val_roc = val_metrics['roc_auc']\n",
    "    val_pr = val_metrics['pr_auc']\n",
    "    \n",
    "    # Save metrics history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_roc_auc'].append(train_roc)\n",
    "    history['train_pr_auc'].append(train_pr)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_roc'].append(val_roc)\n",
    "    history['val_pr'].append(val_pr)\n",
    "    if lr_history:\n",
    "        history['lr'].extend(lr_history)\n",
    "    \n",
    "    # Print progress with current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch:02d}:\")\n",
    "    print(f\"  Train: Loss = {train_loss:.4f}, ROC AUC = {train_roc:.4f}, PR AUC = {train_pr:.4f}\")\n",
    "    print(f\"  Valid: Loss = {val_loss:.4f}, ROC AUC = {val_roc:.4f}, PR AUC = {val_pr:.4f}, LR = {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model state\n",
    "    if val_roc > best_val_roc:\n",
    "        best_val_roc = val_roc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  → New best model saved! ROC AUC: {best_val_roc:.4f}\")\n",
    "\n",
    "# Load the best model state for final evaluation\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Loaded best model with validation ROC AUC: {best_val_roc:.4f}\")\n",
    "\n",
    "# Perform final evaluation\n",
    "final_metrics = evaluate(model, test_loader, device)\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(f\"Test ROC AUC: {final_metrics['roc_auc']:.4f}\")\n",
    "print(f\"Test PR AUC: {final_metrics['pr_auc']:.4f}\")\n",
    "print(f\"Test Loss: {final_metrics['loss']:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model_state, 'best_gin_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3328c",
   "metadata": {
    "id": "a2a3328c"
   },
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb9775",
   "metadata": {
    "id": "cffb9775"
   },
   "outputs": [],
   "source": [
    "# Visualize learning curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(history['train_loss'])+1), history['train_loss'], 'o-', label='Training Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation ROC AUC\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(history['val_roc'])+1), history['val_roc'], 'o-', label='ROC AUC')\n",
    "plt.plot(range(1, len(history['val_pr'])+1), history['val_pr'], 'o-', label='PR AUC')\n",
    "plt.title('Validation Metrics per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36742490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Model Evaluation and Visualization\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions for each task\n",
    "all_true = {}\n",
    "all_pred = {}\n",
    "all_batch_losses = []\n",
    "\n",
    "# Initialize loss function - binary cross entropy with reduction='none' to get per-task losses\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch)  # Raw logits (before sigmoid)\n",
    "        out_probs = torch.sigmoid(out).detach().cpu()\n",
    "        mask = batch.y_mask.cpu()\n",
    "        y = batch.y.cpu()\n",
    "        \n",
    "        # Calculate batch losses per task\n",
    "        batch_loss = loss_fn(out, batch.y)\n",
    "        masked_loss = batch_loss * batch.y_mask\n",
    "        all_batch_losses.append(masked_loss.cpu())\n",
    "        \n",
    "        for task in range(out_probs.size(1)):\n",
    "            # Select only valid entries (where mask is True)\n",
    "            idx = mask[:, task]\n",
    "            if idx.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            true = y[idx, task].numpy()\n",
    "            pred = out_probs[idx, task].numpy()\n",
    "            \n",
    "            all_true.setdefault(task, []).append(true)\n",
    "            all_pred.setdefault(task, []).append(pred)\n",
    "\n",
    "# Calculate training loss per task\n",
    "all_losses = torch.cat(all_batch_losses, dim=0)  # Combine all batch losses\n",
    "valid_samples_per_task = all_losses.ne(0).sum(dim=0).float()\n",
    "task_losses = all_losses.sum(dim=0) / valid_samples_per_task\n",
    "\n",
    "# Calculate AUC for each task\n",
    "task_metrics = {}\n",
    "for task in all_true:\n",
    "    t = np.concatenate(all_true[task])\n",
    "    p = np.concatenate(all_pred[task])\n",
    "    \n",
    "    # Skip if only one class is present\n",
    "    if len(np.unique(t)) < 2:\n",
    "        continue\n",
    "        \n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(t, p)\n",
    "    \n",
    "    # Calculate PR AUC\n",
    "    prec, rec, _ = precision_recall_curve(t, p)\n",
    "    pr_auc = auc(rec, prec)\n",
    "    \n",
    "    # Store task metrics and raw predictions for plotting\n",
    "    task_metrics[task] = {\n",
    "        'roc_auc': roc_auc, \n",
    "        'pr_auc': pr_auc,\n",
    "        'true': t,\n",
    "        'pred': p,\n",
    "        'loss': task_losses[task].item() if task < len(task_losses) else float('nan')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df010063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vs Val Loss and ROC AUC plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Train vs Val Loss\n",
    "axes[0, 0].plot(range(1, len(history['train_loss'])+1), history['train_loss'], 'o-', label='Training Loss', color='blue')\n",
    "axes[0, 0].plot(range(1, len(history['val_loss'])+1), history['val_loss'], 'o-', label='Validation Loss', color='red')\n",
    "axes[0, 0].set_title('Train vs Validation Loss', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "\n",
    "# Train vs Val ROC AUC\n",
    "axes[0, 1].plot(range(1, len(history['train_roc_auc'])+1), history['train_roc_auc'], 'o-', label='Training ROC AUC', color='blue')\n",
    "axes[0, 1].plot(range(1, len(history['val_roc'])+1), history['val_roc'], 'o-', label='Validation ROC AUC', color='green')\n",
    "axes[0, 1].set_title('Train vs Validation ROC AUC', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('ROC AUC', fontsize=12)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_ylim([0.5, 1.0])  # Set y-axis from 0.5 (random) to 1.0 (perfect)\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "\n",
    "# Train vs Val PR AUC\n",
    "axes[1, 0].plot(range(1, len(history['train_pr_auc'])+1), history['train_pr_auc'], 'o-', label='Training PR AUC', color='blue')\n",
    "axes[1, 0].plot(range(1, len(history['val_pr'])+1), history['val_pr'], 'o-', label='Validation PR AUC', color='purple')\n",
    "axes[1, 0].set_title('Train vs Validation PR AUC', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('PR AUC', fontsize=12)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0.0, 1.0])  # PR AUC ranges from 0 to 1\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "axes[1, 1].plot(range(1, len(history['lr'])+1), history['lr'], '-', color='orange')\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Optimization Step', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')  # Log scale for better visualization\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4221e",
   "metadata": {
    "id": "7eb4221e"
   },
   "source": [
    "## 7. Conclusion and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902fe8d",
   "metadata": {
    "id": "5902fe8d"
   },
   "source": [
    "# TODO: Add analysis of results and conclusions"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (gnn-tox21)",
   "language": "python",
   "name": "gnn-tox21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
